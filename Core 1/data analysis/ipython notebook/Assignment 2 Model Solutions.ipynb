{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5227ac9028428d866de7b7ea6a31baed",
     "grade": false,
     "grade_id": "cell-1e44d039b71e9215",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "from __future__ import division\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "from scipy.optimize import *\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9142bce932131d95e53ebc0d9feeb7c8",
     "grade": false,
     "grade_id": "cell-323d988312829e83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1: Poiseuille's method for determining viscosity\n",
    "\n",
    "The  volume flow rate, ${\\displaystyle\\frac{{\\rm d}V}{{\\rm d}t}}$, of fluid flowing smoothly through a horizontal tube of length $L$ and radius $r$ is given by Poiseuille's equation:\n",
    "\\begin{equation}\n",
    "\\frac{{\\rm d}V}{{\\rm d}t}=\\frac{\\pi\\rho g h r^4}{8\\eta L},\n",
    "\\end{equation}\n",
    "where $\\eta$ and $\\rho$ are the viscosity and density, respectively, of the fluid,  $h$ is the head of pressure across the tube, and $g$ the acceleration due to gravity. \n",
    "<bf>\n",
    "In an experiment the graph of the flow rate versus height has a slope measured to 7%, the length is known to 0.5%, and the radius to 8%.  \n",
    "<bf>\n",
    "Required:\n",
    "<bf>\n",
    "<blockquote>\n",
    "(i) What is the fractional precision to which the viscosity is known? \n",
    "<bf>\n",
    "<bf>\n",
    "(ii) If more experimental time is available, should this be devoted to \n",
    ">(a) collecting more flow-rate data, \n",
    "<bf>\n",
    ">(b) measuring the length,  \n",
    "<bf>\n",
    ">(c) the radius of the tube?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71cc68e1261e07016222bb6490f6d904",
     "grade": false,
     "grade_id": "cell-d5b3a1e84a1937df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) What is the fractional precision to which the viscosity is known? Express your answer as a DECIMAL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64620adb11b45aa382ad16b40b78b068",
     "grade": false,
     "grade_id": "cell-6e70cb94c0f6c4fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def one_i():\n",
    "    'Returns fractional precision of viscosity'\n",
    "    \n",
    "    fractional_precision = np.sqrt((16*0.08**2)+(0.07**2)+(0.005**2))\n",
    "    percentage_error = fractional_precision*100\n",
    "    \n",
    "    return fractional_precision\n",
    "one_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "057596ac7a09af47158136c7b372c5f9",
     "grade": false,
     "grade_id": "cell-36b3d5896f5344e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) If more experimental time is available, should this be devoted to \n",
    ">(a) collecting more flow-rate data, \n",
    "<bf>\n",
    ">(b) measuring the length,  \n",
    "<bf>\n",
    ">(c) the radius of the tube?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc70fccc3e9f6f85eb55e98b80f0b1a9",
     "grade": false,
     "grade_id": "cell-34e207a386f2dfeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def one_ii():\n",
    "    '''Your function should return a string of A,B or C'''\n",
    "\n",
    "    comment = 'C'\n",
    "\n",
    "    return comment\n",
    "one_ii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f76858d207563cdd0d34e2a2b88a7a6",
     "grade": false,
     "grade_id": "cell-1b2bf5ae05a8ccb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2: Functional error approach for Van der Waals calculation\n",
    "\n",
    "The Van der Waals equation of state is a correction to the ideal gas law, given by the equation,\n",
    "\n",
    "\\begin{equation}\n",
    "(P+\\frac{a}{V_m^2})(V_m-b) = RT,\n",
    "\\end{equation}\n",
    "\n",
    "where $P$ is the pressure, $V_m$ is the molar volume, $T$ is the absolute temperature, $R$ is the universal gas constant with $a$ and $b$ being species-specific Van der Waals coefficents. \n",
    "\n",
    "A sample of Nitrogen was measured in an experiment as,\n",
    "<bf>\n",
    ">Molar Volume $V_m$ = $(2.000 \\pm 0.003)$x$10^{-4}m^3mol^{-1}$\n",
    "<bf>\n",
    ">Absolute Temperature $T$ = $298.0\\pm0.2K$\n",
    "\n",
    "and the constants are,\n",
    "<blockquote>\n",
    "<bf> \n",
    "$a$ = $(1.408$x$10^{-1}) m^6mol^{-2}Pa$\n",
    "<bf>\n",
    "$b$ = $(3.913$x$10^{-5}) m^3mol^{-1}$\n",
    "<bf>\n",
    "$R$ = $(8.3145) JK^{-1}mol^{-1}$\n",
    "<bf>\n",
    "</blockquote>\n",
    "Required:\n",
    "<bf>\n",
    ">(i) From the given data, calculate the pressure giving your answer in MPa.\n",
    "<bf>\n",
    ">(ii) Calculate the uncertainty in the pressure by using the functional approach for error propagation.\n",
    "<bf>\n",
    ">(iii) Repeat the calculations above for \n",
    ">>$V_m = (2.000\\pm0.003)\\times10^{-3}\\,{\\rm m}^{3}\\,{\\rm mol}^{-1}$ and  $T=400.0 \\pm 0.2K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "595e47dd77e4cbe6d012f96066a3e248",
     "grade": false,
     "grade_id": "cell-4ddf0070b200f4a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) From the given data, calculate the pressure giving your answer in MPa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ad70b22f126f990f54552101c49e603",
     "grade": false,
     "grade_id": "cell-83ea70abed73edc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def two_i():\n",
    "    '''Your function should return the pressure in MPa'''\n",
    "\n",
    "    R = 8.3145\n",
    "    T,alpha_t = 298,0.2\n",
    "    v_m,alpha_vm = 2*10**-4,0.003*10**-4\n",
    "    b = 3.913*10**-5\n",
    "    a = 1.408*10**-1\n",
    "    # Note: the answer is divided by 10**6 in order to have the correct units\n",
    "    pressure = (((R*T)/(v_m-b))-(a/(v_m**2)))/10**6\n",
    "    return pressure\n",
    "two_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c3e0d14dbd94e7f6a4d38ccb43629ad",
     "grade": false,
     "grade_id": "cell-edefca25b0429fc4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) Calculate the uncertainty in the pressure by using the functional approach for error propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c0f6b91aee070601b206b126d16353a",
     "grade": false,
     "grade_id": "cell-584eaae2341d6764",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def two_ii():\n",
    "    '''Your function should return the uncertainty'''\n",
    "\n",
    "    R = 8.3145\n",
    "    T,alpha_t = 298,0.2\n",
    "    v_m,alpha_vm = 2*10**-4,0.003*10**-4\n",
    "    b = 3.913*10**-5\n",
    "    a = 1.408*10**-1\n",
    "    pressure = two_i()*10**6 # pressure is not in Pascals\n",
    "    \n",
    "    alpha_v= ((R*T)/((v_m+alpha_vm)-b))-(a/((v_m+alpha_vm)**2))-pressure\n",
    "    alpha_t = ((R*(T+alpha_t))/(v_m-b))-(a/(v_m**2))-pressure\n",
    "    uncertainty = (np.sqrt((alpha_v**2)+(alpha_t**2)))/10**6\n",
    "    \n",
    "    return uncertainty\n",
    "two_ii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6608fd18524d78c8024e903cceb0a7eb",
     "grade": false,
     "grade_id": "cell-86ed7d58f52fa600",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) Repeat the calculations above for \n",
    ">$V_m = (2.000\\pm0.003)\\times10^{-3}\\,{\\rm m}^{3}\\,{\\rm mol}^{-1}$ and  $T=400.0 \\pm 0.2K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "271554760d5e97a4f3cb81793886acb4",
     "grade": false,
     "grade_id": "cell-c8516e1da652a8c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def two_iii():\n",
    "    '''Your function should return both the pressure and the uncertainty'''\n",
    "    pressure_2 = 0\n",
    "    uncertainty_2 = 0\n",
    "\n",
    "    R = 8.3145\n",
    "    T,alpha_t = 400,0.2\n",
    "    v_m,alpha_vm = 2*10**-3,0.003*10**-3\n",
    "    b = 3.913*10**-5\n",
    "    a = 1.408*10**-1\n",
    "    \n",
    "    pressure_2 = (((R*T)/(v_m-b))-(a/(v_m**2)))\n",
    "    alpha_v= ((R*T)/((v_m+alpha_vm)-b))-(a/((v_m+alpha_vm)**2))-pressure_2\n",
    "    alpha_t = ((R*(T+alpha_t))/(v_m-b))-(a/(v_m**2))-pressure_2\n",
    "    uncertainty_2 = (np.sqrt((alpha_v**2)+(alpha_t**2)))/1000000\n",
    "    pressure_2 = pressure_2/10**6\n",
    "    \n",
    "    return pressure_2,uncertainty_2\n",
    "two_iii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6af3200fad441d2c756a54d45f2500fd",
     "grade": false,
     "grade_id": "cell-f614dc07c0bd1f74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3: Reverse Engineering the Incredible Goal\n",
    "The separation of the posts is 7.32m, and the ball is struck from a point 22m from the near post and 29m from the far post.\n",
    "\n",
    "Required:\n",
    "\n",
    "> (i) Plot a graph of $\\alpha_\\theta$ on the y-axis vs $\\alpha_L$ on the x-axis for the range of values presented in the `alpha_ls` array.\n",
    "<bf>\n",
    ">(ii) To what (common) precision must these three lengths be known to justify quoting the angle to 11 significant figures? \n",
    "\n",
    "*[Hint: use the functional approach using the values for the errors in the length measurements as the provided `alpha_ls` array]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e83e12931af28374d7dc4aba00e09bf7",
     "grade": false,
     "grade_id": "cell-f9e1603d2463326c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Plot a graph of $\\alpha_\\theta$ on the y-axis vs $\\alpha_L$ on the x-axis for the range of values presented in the `alpha_ls` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c6fab62dcc52bcba3947a5362784cbb",
     "grade": false,
     "grade_id": "cell-f0c9d88a7c12b4f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def three_i():\n",
    "    '''Your function should plot the graph and return the alpha_thetas array.'''\n",
    "    \n",
    "    a = 22\n",
    "    b = 29\n",
    "    c = 7.32\n",
    "    alpha_ls = [0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07, 1e-08, 1e-09, 1e-10, 1e-11, 1e-12]\n",
    "    alpha_thetas = []\n",
    "    \n",
    "    # Cosine rule\n",
    "    theta_rad = np.arccos(((b**2)+(c**2)-(a**2))/(2*b*c))\n",
    "\n",
    "    for i in alpha_ls:\n",
    "        error = i\n",
    "        # Perform the functional approach\n",
    "        alpha_az = np.arccos(((b**2)+(c**2)-((a+error)**2))/(2*b*c))-theta_rad\n",
    "        alpha_bz = np.arccos((((b+error)**2)+(c**2)-(a**2))/(2*(b+error)*c))-theta_rad\n",
    "        alpha_cz = np.arccos(((b**2)+((c+error)**2)-(a**2))/(2*b*(c+error)))-theta_rad\n",
    "        alpha_theta = np.sqrt(((alpha_az)**2)+((alpha_bz)**2)+((alpha_cz)**2))\n",
    "        alpha_thetas.append(alpha_theta)\n",
    "    plt.plot(alpha_ls,alpha_thetas)\n",
    "    \n",
    "    #Plot on a log scale\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(r'$\\alpha_L$')\n",
    "    plt.ylabel(r'$\\alpha_\\theta$')\n",
    "    plt.show()\n",
    "\n",
    "    return alpha_thetas\n",
    "three_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f9c9aabebd7a698f8485be83fa64a58",
     "grade": false,
     "grade_id": "cell-f2556656401f0967",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) To what (common) precision must these three lengths be known to justify quoting the angle to 11 significant figures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "124e4678bc6465d940a3d89212674645",
     "grade": false,
     "grade_id": "cell-78953d834d936e7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For the angle to be quoted to 11 significant figures, the error must be in the 10th decimal place (since the angle is in radians and we are assuming the angle to be >1 radian). This is the case first when the error in the angle is 7x$10^{-10}$, which corresponds to a common precision in the lenghts of $10^{-9}$. If the angle were <1 radian then the precision would be $10^{-10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6adfaa68fa76596d1515bc21e12c996",
     "grade": false,
     "grade_id": "cell-383dcdd17f81e8b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 4: Linear Regression/Weighted Fit\n",
    "\n",
    "The data  plotted in Fig 6.1(d) relating to the degradation of the signal to noise ratio from a frequency to voltage converter near harmonics of the mains frequency are listed below.\n",
    "\\begin{equation}\n",
    "\\begin{array}{lcccccc}\n",
    "\\hline\n",
    "{\\rm frequency~(Hz)} &10&20&30&40&50&60\\\\\n",
    "{\\rm voltage~(mV)} &16&45&64&75&70&115\\\\\n",
    "{\\rm error~(mV)}   &5&5&5&5&30&5\\\\\n",
    "\\hline\n",
    "{\\rm frequency~(Hz)} &70&80&90&100&110&\\\\\n",
    "{\\rm voltage~(mV)} &142&167&183&160&221&\\\\\n",
    "{\\rm error~(mV)}   &5&5&5&30&5&\\\\\n",
    "\\hline\n",
    "\\end{array} \n",
    "\\end{equation}\n",
    "\n",
    "This data is also contained in the file 'linear_regression.csv'.\n",
    "\n",
    "Required: \n",
    "<bf>\n",
    "> (i) Calculate the best-fit gradient and intercept and associated errors using a weighted fit. You may use the `curve_fit` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91c938867fd924e6c51dd524a05237ef",
     "grade": false,
     "grade_id": "cell-32e1ed61e45e67ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('linear_regression.csv')\n",
    "frequencies = data.iloc[:,0]\n",
    "voltages = data.iloc[:,1]\n",
    "voltage_errors = data.iloc[:,2]\n",
    "\n",
    "def f(frequencies, a,b):\n",
    "    return a*frequencies+b\n",
    "\n",
    "def best_fit_params():\n",
    "    '''Your function should return the gradient,gradient_error,intercept,intercept_error'''\n",
    "    gradient = 0\n",
    "    gradient_error = 0\n",
    "    intercept = 0\n",
    "    intercept_error = 0\n",
    "\n",
    "    # Using the curve_fit function\n",
    "    popt, pcov = curve_fit(f, frequencies, voltages, sigma = voltage_errors)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    gradient = popt[0]\n",
    "    gradient_error = perr[0]\n",
    "    intercept = popt[1]\n",
    "    intercept_error = perr[1]\n",
    "\n",
    "    return(gradient,gradient_error,intercept,intercept_error)\n",
    "\n",
    "best_fit_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab8603820577447c2b6830c8596db55e",
     "grade": false,
     "grade_id": "cell-2463f408f16e7285",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5: Error bars from a $\\chi^2$ minimisation\n",
    "|--|Unweighted | Weighted |\n",
    "| --- | --- | --- |\n",
    "| Gradient | (1.9$\\pm$0.2)mV/Hz | (2.03$\\pm$0.05)mV/Hz |\n",
    "| Intercept | (0$\\pm$1)x10mV | (-1$\\pm$3)mV |\n",
    "\n",
    "Required:\n",
    "<bf>\n",
    ">(i) For the data set of the previous question, write your own code to perform a $\\chi^2$ minimisation. You may use the `mininmize` function, but not the `curve_fit` function.\n",
    "<bf>\n",
    ">(ii) Verify that $\\chi^{2}_{\\rm{min}}$ is obtained for the same values of the parameters as are listed in the table above. \n",
    "<bf>\n",
    ">(iii) By following the procedure of $\\chi^2\\rightarrow\\chi^2_{\\rm min}+1$ outlined in Section 6.5 in Hughes and Hase and the figure above, check that the error bars for $m$ and $c$ are in agreement with the table above.  Include explicitly the first 5 steps of the procedure shown in the figure above for the calculation of the slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca674655a407000c19cc3db3bf03b760",
     "grade": false,
     "grade_id": "cell-2a79bbac89f91f96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) For the data set of the previous question, write code to perform a $\\chi^2$ minimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('linear_regression.csv')\n",
    "frequencies = data.iloc[:,0]\n",
    "voltages = data.iloc[:,1]\n",
    "voltage_errors = data.iloc[:,2]\n",
    "# Note: it is useful to normalise the data in order to help avoid a large\n",
    "# dependence on the initial starting position\n",
    "voltages = voltages\n",
    "voltage_errors = voltage_errors\n",
    "\n",
    "def chisqfunc(x):\n",
    "    'Linear chi squared fitting function'\n",
    "    a,b = x\n",
    "    model = a + b*frequencies\n",
    "    chisq = np.sum(((voltages - model)/voltage_errors)**2)\n",
    "    return chisq\n",
    "\n",
    "# Set starting position from which to minimize\n",
    "x0 = np.array([0,0])\n",
    "\n",
    "# Use scipy.optimize.minimize\n",
    "result =  minimize(chisqfunc, x0)\n",
    "a,b=result.x\n",
    "\n",
    "# Good practice to plot graph to show the fit to check its quality\n",
    "plt.errorbar(frequencies,voltages, label = 'data', yerr=voltage_errors,fmt='o',capsize=2.5)\n",
    "plt.plot(frequencies,a+b*frequencies, label = 'chi squared fit')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Voltage (mV)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print ('The gradient is {} mV/Hz and the intecept is {} mV'.format(b,a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b26e98fe929f1e3fcd5c278163fa4065",
     "grade": false,
     "grade_id": "cell-bc9febc07dd02b51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note: the fit is good and the only points further away from the line are the two with very large error bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef00da9f8dc33783c7872157d131ec11",
     "grade": false,
     "grade_id": "cell-e346d61d51d8c4ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) Verify that $\\chi^{2}_{\\rm{min}}$ is obtained for the same values of the parameters as are listed in the table above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01299f2da0a3f98edd0015152c02b38c",
     "grade": false,
     "grade_id": "cell-955031cca9017181",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('linear_regression.csv')\n",
    "\n",
    "def five_ii(): \n",
    "    '''Your function must return the gradient and intercept'''\n",
    "    \n",
    "    gradient = b\n",
    "    intercept = a\n",
    "    \n",
    "    return gradient,intercept \n",
    "five_ii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) By following the procedure of $\\chi^2\\rightarrow\\chi^2_{\\rm min}+1$ outlined in Section 6.5 in Hughes and Hase and the figure above, check that the error bars for $m$ and $c$ are in agreement with the table above.  Include explicitly the first 5 steps of the procedure shown in the figure above for the calculation of the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(precision, z_min, f_min):\n",
    "\n",
    "    z_new = z_min\n",
    "    f_new = f_min\n",
    "    m_stop = 0\n",
    "    c_stop = 0\n",
    "    while(m_stop == 0 or c_stop == 0):\n",
    "        m_stop = 1\n",
    "        c_stop = 1\n",
    "        \n",
    "        # There are more optimal ways than doing a while(1) function but this suffices for this solution\n",
    "        while (1):\n",
    "            # changing gradient\n",
    "            z_new[1] = z_new[1] + (1 / precision)\n",
    "\n",
    "            f_new = chisqfunc(z_new)\n",
    "                \n",
    "            if (f_new - f_min) >= 1 :\n",
    "                z_new[1] = z_new[1] - (1 / precision)\n",
    "                break;\n",
    "            else :\n",
    "                m_stop = 0\n",
    "        \n",
    "        while (1):\n",
    "            # changing intercept\n",
    "            z_new[0] = z_new[0] - (1 / precision)\n",
    "\n",
    "            f_new = chisqfunc(z_new)\n",
    "                \n",
    "            if (f_new - f_min) >= 1 :\n",
    "                z_new[0] = z_new[0] + (1 / precision)\n",
    "                break;\n",
    "            else:\n",
    "                c_stop = 0\n",
    "                \n",
    "    return z_new\n",
    "\n",
    "def five_iii():\n",
    "    '''\n",
    "    Adapted from one of the submitted homework solutions - thank you to whoever did this\n",
    "    The function has been adapted to make it slightly more efficient but I liked the custom search function\n",
    "    '''\n",
    "    error_m = 0\n",
    "    error_c = 0\n",
    "    \n",
    "    x0 = [0,0]\n",
    "    result_weight = minimize(chisqfunc, x0)\n",
    "    \n",
    "    precision = 1000\n",
    "    result_shift_weight = search(1000, result_weight.x, result_weight.fun)\n",
    "    \n",
    "    result_weight = minimize(chisqfunc, x0)\n",
    "    \n",
    "    error_m_weight = round(abs(result_shift_weight[1] - result_weight.x[1]), 2)\n",
    "    error_c_weight = round(abs(result_shift_weight[0] - result_weight.x[0]), 0)\n",
    "    \n",
    "    error_m = error_m_weight\n",
    "    error_c = error_c_weight\n",
    "    \n",
    "    return error_m, error_c\n",
    "\n",
    "five_iii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd98e60c814eb432ebd2fc1c5ca7458f",
     "grade": false,
     "grade_id": "cell-5892e776c1a1fd6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 6- Strategies for error bars\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{lccccc}\n",
    "\\hline\n",
    "x &1&2&3&4&5\\\\\n",
    "y &51&103&150&199&251\\\\\n",
    "\\alpha_{y}   &1&1&2&2&3\\\\\n",
    "\\hline\n",
    "x &6&7&8&9&10\\\\\n",
    "y &303&347&398&452&512\\\\\n",
    "\\alpha_{y}   &3&4&5&6&7\\\\\n",
    "\\hline\n",
    "\\end{array} \n",
    "\\end{equation}\n",
    "\n",
    "Required:\n",
    "<bf>\n",
    ">(i) Calculate the weighted best-fit values of the slope, intercept, and their uncertainties.\n",
    "<bf>\n",
    ">(ii) If the data set had been homoscedastic, with all the errors equal, $\\alpha_{y}=4$, calculate the weighted best-fit values of the slope, intercept, and their uncertainties.\n",
    "<bf>\n",
    ">(iii) If the experimenter took greater time to collect the first and last data points, for which $\\alpha_{y}=1$, at the expense of all of the other data points, for which $\\alpha_{y}=8$, calculate the weighted best-fit values of the slope, intercept, and their uncertainties.\n",
    "<bf>\n",
    ">(iv) Comment on your results.\n",
    "<bf>\n",
    ">(v) Plot the original data from the table including error bars. On the same plot, show the fitted function calculated in (i)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a40a0a5b5b293f0bffae292b9a242ead",
     "grade": false,
     "grade_id": "cell-fa3b795eff05d022",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Calculate the weighted best-fit values of the slope, intercept, and their uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eeb1711afeefe5a8151555bbf4581714",
     "grade": false,
     "grade_id": "cell-a139df62925ab4cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "xs = [1,2,3,4,5,6,7,8,9,10]\n",
    "ys = [51,103,150,199,251,303,347,398,452,512]\n",
    "ay = [1,1,2,2,3,3,4,5,6,7]\n",
    "\n",
    "def f(x,a,b):\n",
    "    return(a*x+b)\n",
    "\n",
    "def six_i():\n",
    "    'Returns slope, intercept, slope uncertainty and intercept uncertainty'\n",
    "    errors = [1,1,2,2,3,3,4,5,6,7]\n",
    "    slope = 0\n",
    "    intercept = 0\n",
    "    slope_uncertainty = 0\n",
    "    intercept_uncertainty = 0\n",
    "\n",
    "    popt, pcov = curve_fit(f, xs, ys, sigma = errors,p0 = [49,1.7])\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    slope = popt[0]\n",
    "    intercept = popt[1]\n",
    "    slope_uncertainty = perr[0]\n",
    "    intercept_uncertainty = perr[1]\n",
    "\n",
    "    return slope,intercept,slope_uncertainty,intercept_uncertainty\n",
    "six_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70193906939b159a87c602bf611af0c1",
     "grade": false,
     "grade_id": "cell-2cf49066a36f3481",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) If the data set had been homoscedastic, with all the errors equal, $\\alpha_{y}=4$, calculate the weighted best-fit values of the slope, intercept, and their uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3c722c0bf656dd094fffd94a4f4e061",
     "grade": false,
     "grade_id": "cell-f5c6499718447839",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def six_ii():\n",
    "    errors = [4,4,4,4,4,4,4,4,4,4]\n",
    "    slope = 0\n",
    "    intercept = 0\n",
    "    slope_uncertainty = 0\n",
    "    intercept_uncertainty = 0\n",
    "\n",
    "    popt, pcov = curve_fit(f, xs, ys, sigma = errors)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    slope = popt[0]\n",
    "    intercept = popt[1]\n",
    "    slope_uncertainty = perr[0]\n",
    "    intercept_uncertainty = perr[1]\n",
    "\n",
    "    return slope,intercept,slope_uncertainty,intercept_uncertainty\n",
    "\n",
    "six_ii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca3368dea85db2a201d547ddd74bdf71",
     "grade": false,
     "grade_id": "cell-e5e5e37d74c0bc6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) If the experimenter took greater time to collect the first and last data points, for which $\\alpha_{y}=1$, at the expense of all of the other data points, for which $\\alpha_{y}=8$, calculate the weighted best-fit values of the slope, intercept, and their uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c1ba426ea86e32058e0e46224e1f166",
     "grade": false,
     "grade_id": "cell-18271092a76c1cdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def six_iii():\n",
    "    errors = [1,8,8,8,8,8,8,8,8,1]\n",
    "    slope = 0\n",
    "    intercept = 0\n",
    "    slope_uncertainty = 0\n",
    "    intercept_uncertainty = 0\n",
    "\n",
    "    popt, pcov = curve_fit(f, xs, ys, sigma = errors)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    slope = popt[0]\n",
    "    intercept = popt[1]\n",
    "    slope_uncertainty = perr[0]\n",
    "    intercept_uncertainty = perr[1]\n",
    "    comment = 'In this case, the error on the fit parameters is lower due to reducing the error of these datapoints.'\n",
    "\n",
    "    return slope,intercept,slope_uncertainty,intercept_uncertainty\n",
    "six_iii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1eb035023abec56da7531da7025f6a8c",
     "grade": false,
     "grade_id": "cell-c3d6f9ae23a6627e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iv) Comment on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac300a5ff5bf465dd8fae9ce12a3da71",
     "grade": false,
     "grade_id": "cell-162101fe22004dafb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Comparing the uncertainties of the fits found in parts (i), (ii) and (iii), we find that the uncertainty on the slope is smallest for (iii). I.e. having small uncertainties for the extremal points is important for a good determination of the slope. Precise measurements of the data points close to x=0 reduce the uncertainty on the intercept. This is why we find relatively small (and similar) uncertainties on the intercept in scenarios (i) and (iii), where the uncertainty on the y-position of the x=1 data point is 1 in both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de005cc6461b4927a318292181d90fe6",
     "grade": false,
     "grade_id": "cell-2c27343e9e9ce7c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (v) Plot the original data from the table including error bars. On the same plot, show the fitted function calculated in (i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bbdae65fa02c88d3d08ec34b155bedf",
     "grade": false,
     "grade_id": "cell-d1838012ecd2aba5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m,c,_,_ = six_i()\n",
    "plt.errorbar(xs,ys,yerr=ay,fmt='o',capsize=2.5, label = 'data')\n",
    "plt.plot(np.arange(11),m*np.arange(11)+c, label = 'weighted fit')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
