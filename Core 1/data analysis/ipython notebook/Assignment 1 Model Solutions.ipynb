{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "477ec9984d203f955a6e702aec7d4f29",
     "grade": false,
     "grade_id": "cell-5df98e2c42315dfd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data Analysis Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9960969f27771913cfa899aaf364719",
     "grade": false,
     "grade_id": "cell-6880a7a39f660792",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "from scipy.special import erf\n",
    "from scipy.special import erfc\n",
    "from math import factorial as factorial\n",
    "from random import seed\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0707dc5164c4883d66c8d5c8fa04a49",
     "grade": false,
     "grade_id": "cell-391591ed0633fc70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1: Mean, Standard Deviation and Standard Error\n",
    "\n",
    "12 measurements of the sensitivity of a photo diode circuit (in Amps/Watt) are: \n",
    "<bf>\n",
    "11.45, 10.91, 11.60, 10.59, 10.32, 10.34, 11.00, 10.94, 11.67, 11.67, 11.06, and 10.57. \n",
    "<bf>\n",
    "Calculate:\n",
    "<blockquote>\n",
    "<bf>\n",
    "(i) The Mean.\n",
    "<bf>\n",
    "(ii) The Standard Deviation.\n",
    "<bf>\n",
    "(iii) The Standard Error.\n",
    "<bf>\n",
    "(iv) How would you report the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3a318615d7e5cfcf30ecf3fe2d6c239",
     "grade": false,
     "grade_id": "cell-23fb767aff3c3ff7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Calculate the Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a0cee813bfa9c5d5f6a9b77b43b3b4c",
     "grade": false,
     "grade_id": "cell-1f30bb7600418b90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = [11.45, 10.91, 11.60, 10.59, 10.32, 10.34, 11.00, 10.94, 11.67, 11.67, 11.06, 10.57]\n",
    "\n",
    "def one_i(data):\n",
    "    '''Return the mean'''\n",
    "    mean = np.mean(data)\n",
    "\n",
    "    return mean\n",
    "\n",
    "# Please print output of functions to make marking easier\n",
    "one_i(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46cead234477cddc20427ed0162ad648",
     "grade": false,
     "grade_id": "cell-539feb16e1c24dc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) Calculate the sample Standard Deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "270fc7943054ceb513dd792fdb39dbdf",
     "grade": false,
     "grade_id": "cell-a39132967e02e09f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = [11.45, 10.91, 11.60, 10.59, 10.32, 10.34, 11.00, 10.94, 11.67, 11.67, 11.06, 10.57]\n",
    "\n",
    "def one_ii(data):\n",
    "    '''Return the standard deviation'''\n",
    "    standard_deviation = np.std(data,ddof = 1)\n",
    "\n",
    "    return(standard_deviation)\n",
    "    \n",
    "one_ii(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86612716c7292479aebb7f71a4755d4f",
     "grade": false,
     "grade_id": "cell-a199c2d3eaaeabaf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) Calculate the Standard Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d2c100e0a7b890f34c511f6aa0c7b1c",
     "grade": false,
     "grade_id": "cell-d98d2b7fc610d222",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = [11.45, 10.91, 11.60, 10.59, 10.32, 10.34, 11.00, 10.94, 11.67, 11.67, 11.06, 10.57]\n",
    "\n",
    "def one_iii(data):\n",
    "    '''Return the standard error'''\n",
    "    st_dev = one_ii(data)\n",
    "    n = len(data)\n",
    "    standard_error = st_dev/np.sqrt(n)\n",
    "\n",
    "    return(standard_error)\n",
    "\n",
    "one_iii(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a93724bd870ef5628f05d35158fb7cb",
     "grade": false,
     "grade_id": "cell-49744f7c13a892eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iv) How would you report the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5f46ec2b4827af7e5b983467a1da984",
     "grade": false,
     "grade_id": "cell-466eee4d73c04131",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The sensitivity of the photo diode is 11.01 $\\pm$ 0.14 Amps/Watt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "505e224fc693f9c0dfff3259747a97b5",
     "grade": false,
     "grade_id": "cell-9d6e425a0d20717a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2: Error in the error\n",
    "\n",
    "Consider a set of measurements with the standard error calculated to be $\\alpha=0.987654321$.  Here we address the question of how many significant figures should be quoted.  \n",
    "\n",
    "Required:\n",
    "<blockquote>\n",
    "\n",
    "(i) Using pandas or any other software package, make a CSV file with four columns.  The first column should be $N$, the number of measurements on which $\\alpha$ is based.  In the second column write $\\alpha$ to the nine significant figures quoted above. The third and fourth columns should be ${\\displaystyle \\alpha\\left(1-\\frac{1}{\\sqrt{2N-2}}\\right)}$    and  ${\\displaystyle \\alpha\\left(1+\\frac{1}{\\sqrt{2N-2}}\\right)}$, respectively.  As we are interested in the variation over a large dynamic range, choose values for $N$ such as 2, 3, 5, 10, 20, 30, etc. \n",
    "<bf>\n",
    "(ii) Verify the statement from Section 2.7.1 that the number of data points,  N , needs to approach a few tens of thousands before the second significant figure in the error can be quoted, i.e. when the values in the three columns become equal to the second significant figure. Use the model that you constructed in the previous part of the question and make appropiate comments using data\n",
    "<bf>\n",
    "(iii) Repeat the analysis for the case where α=0.123456789, i.e. the first significant digit of the error is 1. Make appropiate comments.\n",
    "<bf>\n",
    "(iv) How many data points must be collected before the third significant figure can be quoted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b8739a13aa9c9f7c1cde7f0c2cbd5d2",
     "grade": false,
     "grade_id": "cell-d599e98cff358ee3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Using pandas or any other software package, make a CSV file with four columns.  The first column should be $N$, the number of measurements on which $\\alpha$ is based.  In the second column write $\\alpha$ to the nine significant figures quoted above. The third and fourth columns should be ${\\displaystyle \\alpha\\left(1-\\frac{1}{\\sqrt{2N-2}}\\right)}$    and  ${\\displaystyle \\alpha\\left(1+\\frac{1}{\\sqrt{2N-2}}\\right)}$, respectively.  As we are interested in the variation over a large dynamic range, choose values for $N$ such as 2, 3, 5, 10, 20, 30, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6880e394e2dc23b09e705bd64da7a5f",
     "grade": false,
     "grade_id": "cell-5685d54128931f32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this is one way in which this can be done efficiently, although there are many other ways\n",
    "# of coding the solution\n",
    "\n",
    "N_range = np.logspace(1,10, base=5, num=10).astype(int)\n",
    "alpha = 0.987654321*np.ones(len(N_range))\n",
    "\n",
    "def make_dataframe(N_range, alpha, outname):\n",
    "    'Creates a pandas dataframe and saves the output as a csv file given a range of N values, and a given alpha'\n",
    "    \n",
    "    plus_fn = lambda N: 1+(1/np.sqrt(2*N - 2))\n",
    "    minus_fn = lambda N: 1-(1/np.sqrt(2*N - 2))\n",
    "    \n",
    "    # Note: using the numpy library where possible is often a good idea since it has in-build\n",
    "    # automatic parallelisation. By mapping a lambda function over a numpy array the same operation\n",
    "    # can be carried out on each element very efficiently.\n",
    "    \n",
    "    alpha_plus = alpha*plus_fn(N_range)\n",
    "    alpha_minus = alpha*minus_fn(N_range)\n",
    "    \n",
    "    # create dictionary\n",
    "    data = {'N':N_range, 'alpha': alpha, 'alpha minus': alpha_minus, 'alpha plus': alpha_plus}\n",
    "    \n",
    "    # create dataframe from dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(outname)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = make_dataframe(N_range, alpha, 'two_i.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99aac8769d8631012737cc92cae77fe9",
     "grade": false,
     "grade_id": "cell-5993b07c1f78a9e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) Verify the statement from Section 2.7.1 that the number of data points,  N , needs to approach a few tens of thousands before the second significant figure in the error can be quoted, i.e. when the values in the three columns become equal to the second significant figure. Use the model that you constructed in the previous part of the question and make appropiate comments using data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36611afe6bb7a0e56e60c7243ae07961",
     "grade": false,
     "grade_id": "cell-8edb0ac5616390a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From the table above it can be seen that the numbers in the final 3 columns only begin to agree to the second significant figure at ~ N = 70000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c849acec52b7f6e6ce18c095e04d286c",
     "grade": false,
     "grade_id": "cell-f75cd98f6880a76d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) Repeat the analysis for the case where  α=0.123456789, i.e. the first significant digit of the error is 1. Make appropiate comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03dee638bbae79dc9b0fe477335afc6e",
     "grade": false,
     "grade_id": "cell-ad0077e159c79c1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N_range = np.logspace(1,10, base=5, num=10).astype(int)\n",
    "alpha = 0.123456789*np.ones(len(N_range))\n",
    "\n",
    "df = make_dataframe(N_range, alpha, 'two_ii.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a24e706cc2bd26987472c1272694bf27",
     "grade": false,
     "grade_id": "cell-1c70bc5924d3bf12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It can be seen from the table above that the values of the final 3 columns agree to two significant figures at only ~ N = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fe325c0df9f6bfcebb95381e4bfdfa4",
     "grade": false,
     "grade_id": "cell-777db7dee58f70c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iv) How many data points must be collected before the third significant figure can be quoted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above table the point at which the numbers agree to three significant figures is somewhere\n",
    "# between ~ 2000000 and 9500000. I therefore ajust my search range in to this region\n",
    "\n",
    "N_range = np.logspace(9,10, base=5, num=10).astype(int)\n",
    "alpha = 0.123456789*np.ones(len(N_range))\n",
    "\n",
    "df = make_dataframe(N_range, alpha, 'two_iv.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b966aefbf7086262a82e1d47f8298580",
     "grade": false,
     "grade_id": "cell-16c1501b47df208b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It can be seen from the table above that the final 3 columns agree to three significant figures at ~ N = 4700000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88560496c95a4d4a9959095a3e2e7309",
     "grade": false,
     "grade_id": "cell-c835d3c4ea562667",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3: Confidence limits for a Gaussian Distribution\n",
    "\n",
    "|Centred on Mean | Measurements within range | Measurements outside range |\n",
    "| --- | --- | --- |\n",
    "| $\\pm\\sigma$ | 68% | 32% |\n",
    "| $\\pm1.65\\sigma$ | 90% | 10% |\n",
    "| $\\pm2\\sigma$ | 95% | 5% |\n",
    "| $\\pm2.58\\sigma$ | 99% | 1% |\n",
    "| $\\pm3\\sigma$ | 99.7% | 0.3% |\n",
    "\n",
    "(i) Verify the results of the above table for the fraction of the data which lies within different ranges of a Gaussian probability distribution function. \n",
    "<bf>\n",
    "(ii) What fraction of the data lies outside the following ranges from the mean? \n",
    "<blockquote>\n",
    "<bf>\n",
    "(a) $\\pm4\\sigma$ \n",
    "<bf>\n",
    "(b) $\\pm5\\sigma$.  \n",
    "</blockquote>\n",
    "\n",
    "(iii) What is the (symmetric) range within which the following fractions of the data lie, leaving your answer in terms of $\\sigma$? \n",
    "<blockquote>\n",
    "<bf>\n",
    "(a) 50% \n",
    "<bf>\n",
    "(b) 99.9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7784359f763723d29e91a95caa10ebc4",
     "grade": false,
     "grade_id": "cell-6b9340cab837f845",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Verify the results of the above table for the fraction of the data which lies within different ranges of a Gaussian probability distribution function. You must return your answers as an ARRAY OF PERCENTAGES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19a3a518fc2063bf7a51157febe3cf07",
     "grade": false,
     "grade_id": "cell-cb3b3ea0dd967211",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def three_i():\n",
    "    '''Return the measurements in range as an array. '''\n",
    "    \n",
    "    measurements_in_range = []\n",
    "    sigma_multiples = [1,1.65,2,2.58,3]\n",
    "    mean = 10\n",
    "    st_dev = 3\n",
    "    \n",
    "    for i in sigma_multiples:\n",
    "        x_1 = ((mean+(i*st_dev))-mean)/((np.sqrt(2)*st_dev))\n",
    "        x_2 = ((mean-(i*st_dev))-mean)/((np.sqrt(2)*st_dev))\n",
    "        measurements_element = (0.5*(1+erf(x_1)))-(0.5*(1+erf(x_2)))\n",
    "        measurements_in_range.append(measurements_element*100)\n",
    "    \n",
    "    return measurements_in_range\n",
    "\n",
    "three_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de0566d36837c1d325d9632c461d57b8",
     "grade": false,
     "grade_id": "cell-556fd501de70283d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) What fraction of the data lies outside the following ranges from the mean? You must return your answer as a PERCENTAGE.\n",
    "<blockquote>\n",
    "<bf>\n",
    "(a) $\\pm4\\sigma$ \n",
    "    \n",
    "<bf>\n",
    "(b) $\\pm5\\sigma$.  \n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c8a3604e9790e36d6b4f8499f70608f",
     "grade": false,
     "grade_id": "cell-b7cac0e7b716f636",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def three_iia():\n",
    "    '''Return the fraction of measurements outside the range as a PERCENTAGE'''\n",
    "    \n",
    "    mean = 10\n",
    "    st_dev = 3\n",
    "    x_1 = ((mean+(4*st_dev))-mean)/((np.sqrt(2)*st_dev))\n",
    "    x_2 = ((mean-(4*st_dev))-mean)/((np.sqrt(2)*st_dev))\n",
    "    four_sigma = (0.5*(1+erf(x_1)))-(0.5*(1+erf(x_2)))\n",
    "    outside_range = (1-four_sigma)*100\n",
    "    \n",
    "    return outside_range\n",
    "   \n",
    "\n",
    "def three_iib():\n",
    "    '''Return the fraction of measurements outside the range as a PERCENTAGE'''\n",
    "    \n",
    "    mean = 10\n",
    "    st_dev = 3\n",
    "    x_1 = ((mean+(5*st_dev))-mean)/((np.sqrt(2)*st_dev))\n",
    "    x_2 = ((mean-(5*st_dev))-mean)/((np.sqrt(2)*st_dev))\n",
    "    five_sigma = (0.5*(1+erf(x_1)))-(0.5*(1+erf(x_2)))\n",
    "    outside_range = (1-five_sigma)*100\n",
    "    \n",
    "    return outside_range\n",
    "\n",
    "three_iia(), three_iib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "379de314131efdd2119b809dd58869a4",
     "grade": false,
     "grade_id": "cell-94af1f6921d1ba1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) What is the (symmetric) range within which the following fractions of the data lie, leaving your answer in terms of $\\sigma$?\n",
    "<blockquote>\n",
    "<bf>\n",
    "(a) 50% \n",
    "<bf>\n",
    "(b) 99.9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46788c9a6b14e1dda72dbcd935b426ee",
     "grade": false,
     "grade_id": "cell-704b8818ac876d40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    'Cumulative distribution function for the standard normal distribution'\n",
    "    # Note: this function is needed to account for the difference\n",
    "    # in error function definitions between Huges and Hayes and the\n",
    "    # scipy library\n",
    "    return (1.0 + erf(x / np.sqrt(2.0))) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af425ec4e2f039aec6794def862987eb",
     "grade": false,
     "grade_id": "cell-ea06e70d0156df5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def three_iiia():\n",
    "    '''Return the multiple of sigma'''\n",
    "    \n",
    "    test_range = np.arange(0,10,0.001)\n",
    "    for i in test_range:\n",
    "        solution = i\n",
    "        if phi(i)-phi(-i) > 0.5:\n",
    "            break\n",
    "    \n",
    "    return solution\n",
    "    \n",
    "\n",
    "def three_iiib():\n",
    "    '''Return the multiple of sigma'''\n",
    "    \n",
    "    test_range = np.arange(0,10,0.001)\n",
    "    for i in test_range:\n",
    "        solution = i\n",
    "        if phi(i)-phi(-i) > 0.999:\n",
    "            break\n",
    "    return solution\n",
    "\n",
    "three_iiia(), three_iiib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Identifying a Potential Outlier\n",
    "\n",
    "Seven successive measurements of the charge stored on a capacitor (all in $\\mu C$) are: \n",
    "<bf>\n",
    "45.7, 53.2, 48.4, 45.1, 51.4, 62.1 and 49.3. \n",
    "<bf>\n",
    "The sixth reading appears anomalously large. \n",
    "\n",
    "Required:\n",
    "<blockquote>\n",
    "(i) Apply Chauvenet’s criterion to ascertain whether this data point should be rejected. In the comment, you must state 'ACCEPT' or 'REJECT'. \n",
    "</blockquote>\n",
    "<blockquote>\n",
    "(ii) Having decided whether to keep 6 or 7 data points, calculate:\n",
    "<bf>\n",
    "<blockquote>\n",
    "(a) The Mean\n",
    "</blockquote>\n",
    "<bf>\n",
    "<blockquote>\n",
    "(b) Standard Deviation\n",
    "</blockquote>\n",
    "<bf>\n",
    "<blockquote>\n",
    "(c) Error of the Charge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45a577add978f832cfeed6362d2f6cb8",
     "grade": false,
     "grade_id": "cell-7b14766c8e43ccd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Apply Chauvenet’s criterion to ascertain whether this data point should be rejected. In the comment, you must state 'ACCEPT' or 'REJECT'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_i():\n",
    "    '''Your function must return the probability of an outlier, n_out and your comment to ACCEPT or REJECT'''\n",
    "    \n",
    "    data = [45.7, 53.2, 48.4, 45.1, 51.4, 62.1, 49.3]\n",
    "    \n",
    "    suspicious_position = 5 # position in the data point array of suspicious result\n",
    "    \n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1)\n",
    "    \n",
    "    # select the upper and lower bounds of the error function integral\n",
    "    x_1 = mean - data[suspicious_position]\n",
    "    x_2 = mean + data[suspicious_position]\n",
    "    \n",
    "    P_out = 1 - (phi(x_2/std) - phi(x_1/std)) # probability of finding a value outside the bounds\n",
    "    # note: the error function assumes a standard deviation of 1 and so the upper and lower bounds\n",
    "    # must be divided by the standard deviation - see definintion of error function and it's scipy implementation\n",
    "    n_out = P_out*len(data)\n",
    "    \n",
    "    comment = 'ACCEPT'\n",
    "    if n_out < 0.5:\n",
    "        comment = 'REJECT'\n",
    "        \n",
    "    return P_out, n_out, comment\n",
    "\n",
    "four_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddc9eeecacb1e1481472956be411fd44",
     "grade": false,
     "grade_id": "cell-5414540ba84410ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iia) Having decided whether to keep 6 or 7 datapoints, calculate the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc01355ce3657e47031ffc9a63e7c7a0",
     "grade": false,
     "grade_id": "cell-57df2747e1fa2468",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def four_iia():\n",
    "    '''Your function should return the mean'''\n",
    "    data_points_1 = [45.7, 53.2, 48.4, 45.1, 51.4, 49.3]\n",
    "    mean = np.mean(data_points_1)\n",
    "    return mean\n",
    "\n",
    "four_iia()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c69a038b7be64d53d469805b078049b",
     "grade": false,
     "grade_id": "cell-441fa0b8a14d768d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iib) Having decided whether to keep 6 or 7 datapoints, calculate the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd24b51f7562631e7827dff480a8bb4c",
     "grade": false,
     "grade_id": "cell-c516a3dbbe1b564d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def four_iib():\n",
    "    '''Your function should return the standard deviation'''\n",
    "\n",
    "    data_points_2 = [45.7, 53.2, 48.4, 45.1, 51.4, 49.3]\n",
    "    standard_deviation = np.std(data_points_2,ddof = 1)\n",
    "    return standard_deviation\n",
    "\n",
    "four_iib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acbaa8661cd875df57b01c0aa4622c5a",
     "grade": false,
     "grade_id": "cell-6f50253083fc8efb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iic) Having decided whether to keep 6 or 7 datapoints, calculate the standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d73e852ac816aa10279c13206defd4c3",
     "grade": false,
     "grade_id": "cell-72bdab1dc4e58cb5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def four_iic():\n",
    "    '''Your function should return the standard error'''\n",
    "\n",
    "    data_points_3 = np.array([45.7, 53.2, 48.4, 45.1, 51.4, 49.3])\n",
    "    st_dev = four_iib()\n",
    "    standard_error = st_dev/(np.sqrt(len(data_points_3)))\n",
    "    \n",
    "    return standard_error\n",
    "\n",
    "four_iic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd5e695a99dbfbd8afc49a51b37eeb7f",
     "grade": false,
     "grade_id": "cell-a152b676ad381ebc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 5: Poisson and Gaussian\n",
    "\n",
    "Required:\n",
    "<bf>\n",
    "<blockquote>\n",
    "(i) Plot a histogram of a Poisson distribution with mean 35.  \n",
    "<bf>\n",
    "</blockquote>\n",
    "<blockquote>\n",
    "(ii) Using the same axes plot the continuous function of a Gaussian with a mean of 35, and standard deviation $\\sqrt{35}$.  \n",
    "</blockquote>\n",
    "<bf>\n",
    "<blockquote>\n",
    "(iii) Comment on the similarities and differences between the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d602e202596fb8f069aa09f1421e7efe",
     "grade": false,
     "grade_id": "cell-15b2117e9f2f7163",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Plot a histogram of a Poisson distribution with mean 35.  \n",
    "<bf>\n",
    "### (ii) Using the same axes plot the continuous function of a Gaussian with a mean of 35, and standard deviation $\\sqrt{35}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_i_and_ii():\n",
    "    '''This function should plot the appropiate histograms'''\n",
    "\n",
    "    mean = 35\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    # Poisson distribution\n",
    "    poisson_data = np.random.poisson(lam=35,size=100000)\n",
    "    color = 'tab:blue'\n",
    "    # plot normalised histogram with integer bins\n",
    "    # in order to avoid the bins beginning on the integers, the bins are shifted by 0.5\n",
    "    ax1.hist(poisson_data, density=True, bins = np.arange(0.5,70.5), label = 'Poisson', color=color)\n",
    "    ax1.set_ylabel('Poisson units')\n",
    "    ax1.set_ylim(0)\n",
    "    \n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    \n",
    "    # Gaussian distribution\n",
    "    st_dev = np.sqrt(35)\n",
    "    gaussian = lambda i: (1/(st_dev*np.sqrt(2*np.pi)))*np.exp((-(i-mean)**2)/(2*st_dev**2))\n",
    "    data = np.arange(0,70) # range over which the Gaussian will be plotted\n",
    "    gaussian_data = gaussian(data)\n",
    "    color = 'tab:red'\n",
    "    ax2.plot(data, gaussian_data, label = 'Gaussian', color=color)\n",
    "    ax2.set_ylabel('Gaussian units')\n",
    "    ax2.set_ylim(0)\n",
    "    \n",
    "    fig.legend(bbox_to_anchor=(0.45, 0.4, 0.4, 0.5)) # set location of legend\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "five_i_and_ii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e670d8324b0291a381638563cc07239d",
     "grade": false,
     "grade_id": "cell-5fa38a2ed1140bbb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) Comment on the similarities and differences between the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3e6f785b32dbba640d50b622d776e95",
     "grade": false,
     "grade_id": "cell-9806cc011bb8f9fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Similarities:\n",
    "- Same height peak\n",
    "- Same general distribution shape at a large number of points (note the apparent shift of the Poisson distribution to the left is due to the fact that the Poisson distribution takes cannot accept negative numbers and will therefore naturally by skewed to the left)\n",
    "\n",
    "Differences:\n",
    "- The Gaussian distribution is continuous, whereas the Poisson is discrete\n",
    "- The Poisson distribution only extends over non-negative integers, whereas the Gaussian distribution extents over all real numbers\n",
    "- The Poisson distribution has a natural left skewness as mentioned above, although the result tends to a Gaussian as you add more points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6aca655aa0a17185198e6b00c21d379",
     "grade": false,
     "grade_id": "cell-3d52d5b0d0b4c916",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "## Question 6: Bumps that go missing\n",
    "\n",
    "(Some of this text is from a Physics World article: http://physicsworld.com/cws/article/news/2016/apr/19/theorizing-about-the-lhcs-750-gev-bump)\n",
    "<bf>\n",
    "Last year, the LHC's ATLAS and CMS experiments both reported a small 'bump' in their data that denoted an excess of photon pairs with a combined mass of around 750 GeV. As this unexpected bump could be the first hint of a new massive particle that is not predicted by the Standard Model of particle physics, the data generated hundreds of theory papers that attempt to explain the signal.  Taking into account what is known as the look-elsewhere effect, CMS says it has seen an excess with a statistical significance of 1.6$\\sigma$, while ATLAS reports a significance of about 2$\\sigma$ –- corresponding, respectively, to a roughly 1 in 10 and 1 in 20 chance that the result is a fluke.\n",
    "\n",
    "While these levels are far below the 5$\\sigma$ 'gold standard' that must be met to claim a discovery, the fact that both collaborations saw a bump at the same energy has excited theoretical physicists.}\n",
    "<bf>\n",
    "From the Cern Courier, October 2016:\n",
    "<bf>\n",
    "\n",
    "![title](figure_1A.JPG)\n",
    "\n",
    "> In a dramatic parallel session, both ATLAS and CMS revealed that their 2016 data do not confirm the previous hints of a diphoton resonance at 750 GeV (figure 1); apparently, those hints were nothing more than tantalising statistical fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f62d19f022b323922e6db558ada9e772",
     "grade": false,
     "grade_id": "cell-8889d8d01c6e630b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Write two sentences explaining what the 'look-elsewhere effect' is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c5e55af7e217fde8a80f86edb834c87",
     "grade": false,
     "grade_id": "cell-30cffe9ac982d5eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The look-elsewhere effect states that, when collecting large amounts of data, you are increasingly likely to find at least one event that is many standard deviations away from the mean. For example, in normally distributed data, there is approximately a 0.3% chance of finding data three standard deviations away from the mean. When collecting large amounts of data, such as that taken in the Large Hadron Collider, the chance of finding such significant data becomes much higher since e.g. when collecting 1,000,000 data points, you are likely to find 3,000 events at the three sigma level. This does not necessarily mean you have discovered a new particle, rather it may mean that you have randomly happened upon a significant event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b38f5aff9c3346f0f5bf1b5ff608dc3b",
     "grade": false,
     "grade_id": "cell-2e88022412e9a1a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) There  are typically more than 100 papers a year from these detectors, each of which has up to 10 histograms, each of which has 50-100 bins.  Assuming that there are $10^5$ bins in a year, how many 2, 3, 4 and 5$\\sigma$ events will there be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84c2e709b921a11ca163972eed35bf13",
     "grade": false,
     "grade_id": "cell-e13b59565cda93f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def six_ii():\n",
    "    '''Your function should return the number of 2,3,4,5 sigma events'''\n",
    "    bins = 10**5\n",
    "    \n",
    "    # function to calculate the number of bins at a given sigma significance\n",
    "    num_bins = lambda bins, sigma: (1-(phi(sigma)-phi(-sigma)))*bins\n",
    "    \n",
    "    two_sigma = num_bins(bins,2)\n",
    "    three_sigma = num_bins(bins,3)\n",
    "    four_sigma = num_bins(bins,4)\n",
    "    five_sigma = num_bins(bins,5)\n",
    "\n",
    "    return two_sigma, three_sigma, four_sigma, five_sigma\n",
    "\n",
    "six_ii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21a11d10a6c49951a1d10423d89ce474",
     "grade": false,
     "grade_id": "cell-f2637be9d590717a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) What are the chances of two 2$\\sigma$ events at the same energy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f48d2dbcf71fbb454602cf3fa798a7fb",
     "grade": false,
     "grade_id": "cell-5330b85f7d1a5c67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Although this question asked for a calculation, it is fine to explain your answer logically in words.\n",
    "\n",
    "We assume the question is asking what the chance of finding two 2 sigma bins are where each of the two significant bins are in different plots and that they are at the same energy. In this case, given that there are expected to be around 4500 such bins across 1000 histograms there are expected to be 4-5 significant bins per histogram. Additionally, there are 499500 ways of choosing 2 different histograms out of the 1000 we have and given two histograms have been chosen there is a 16-20% chance of having one bin in each where there are significant events at the same energy. Therefore, the chance of finding two 2 sigma events at the same energy is incredibly likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "482d3e85d9f260909214bd299e4930f9",
     "grade": false,
     "grade_id": "cell-b1ef0244c2c5e2c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Coding Exercise\n",
    "\n",
    "Choose one of the distributions we discussed in the context of the Central Limit theorem: either the uniform distribution, the triangular distribution or a Gaussian distribution. They should span the interval 0 to 1.\n",
    "<bf>\n",
    "Write code that allows you to choose numbers at random from this distribution. Then,\n",
    "\n",
    "<blockquote>\n",
    "<bf>\n",
    "(i) Choose 1,000 numbers at random, and plot a histogram of their occurrences.\n",
    "</blockquote>\n",
    "<bf>\n",
    "<blockquote>\n",
    "(ii) Choose 2 numbers from  the distribution at random, and average them.  Repeat this 1,000 times and plot a histogram.\n",
    "<bf>\n",
    "</blockquote>\n",
    "<blockquote>\n",
    "(iii) Do the same for the sum of 3, 4 and 5 numbers, and make the corresponding plots.\n",
    "<bf>\n",
    "</blockquote>\n",
    "<blockquote>\n",
    "(iv) Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4689a54bb227253a7513759989b9578",
     "grade": false,
     "grade_id": "cell-0571ee7f7d7263e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = np.random.uniform(size = 1000)\n",
    "\n",
    "def averaging(data, num_to_average):\n",
    "    data = np.array(data) # ensure data is in a numpy array format\n",
    "    averaged_data = []\n",
    "    for i in range(1000):\n",
    "        # select the desired number of indices at random to determine the position the elements to be averaged\n",
    "        indices = np.random.randint(0, len(data), size=num_to_average)\n",
    "        averaged_data.append(np.mean(data[indices]))\n",
    "    return averaged_data\n",
    "\n",
    "plt.hist(data, bins='auto')\n",
    "plt.title('Uniformly distributed')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "nums_to_average = [2,3,4,5]\n",
    "\n",
    "for i in nums_to_average:\n",
    "    averaged_data = averaging(data,i)\n",
    "    plt.hist(averaged_data, bins='auto')\n",
    "    plt.title('Uniformly distributed with {} averaged points'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "085ca8f3a92e2452a21e4b80ce9c6398",
     "grade": false,
     "grade_id": "cell-67d8356d201791ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iv) Comment on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2826e4821c74be7265fb2ff5d86a1a8e",
     "grade": false,
     "grade_id": "cell-1419c5cc8e817aa2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The distribution increasingly approaches a normal distribution as more points are averaged over. This is a consequence of the Central Limit Theorem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
