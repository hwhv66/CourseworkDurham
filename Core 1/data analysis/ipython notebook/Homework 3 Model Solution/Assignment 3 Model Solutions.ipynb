{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c162cf76503771ffa4131a20daafb3be",
     "grade": false,
     "grade_id": "cell-ed258371d1aaae62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "from __future__ import division\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "from scipy.optimize import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8711d0359cfec4e290f88c84962a51c3",
     "grade": false,
     "grade_id": "cell-b5dd6a19dbfc0109",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 1: Linear Regression, Curvature Matrix\n",
    "\n",
    "Consider the data listed below,\n",
    "\\begin{equation}\n",
    "\\begin{array}{lcccccc}\n",
    "\\hline\n",
    "{\\rm frequency~(Hz)} &10&20&30&40&50&60\\\\\n",
    "{\\rm voltage~(mV)} &16&45&64&75&70&115\\\\\n",
    "{\\rm error~(mV)}   &5&5&5&5&30&5\\\\\n",
    "\\hline\n",
    "{\\rm frequency~(Hz)} &70&80&90&100&110&\\\\\n",
    "{\\rm voltage~(mV)} &142&167&183&160&221&\\\\\n",
    "{\\rm error~(mV)}   &5&5&5&30&5&\\\\\n",
    "\\hline\n",
    "\\end{array} \n",
    "\\end{equation}\n",
    "\n",
    "This data is also contained in the file 'linear_regression.csv'.\n",
    "\n",
    "Required:\n",
    "<bf>\n",
    "> (i) Calculate the 4 elements of the curvature matrix.\n",
    "<bf>\n",
    "> (ii) Invert this to give the error matrix.\n",
    "<bf>\n",
    "> (iii) What are the uncertainties in the slope and intercept?\n",
    "<bf>\n",
    "> (iv) Comment on your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fea2736884b39c9f236829e75cbd5c8",
     "grade": false,
     "grade_id": "cell-0ecbd3712337b9ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Calculate the 4 elements of the curvature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61562713371b818077e70d8a83834891",
     "grade": false,
     "grade_id": "cell-a8061423011a8a5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('linear_regression.csv')\n",
    "frequencies = data.iloc[:,0]\n",
    "voltages = data.iloc[:,1]\n",
    "voltage_errors = data.iloc[:,2]\n",
    "\n",
    "def one_i():\n",
    "    '''Your function should return something of the form np.matrix([[a_cc,a_cm],[a_mc,a_mm]])'''\n",
    "    \n",
    "    a_cc = 0\n",
    "    a_cm = 0\n",
    "    a_mm = 0\n",
    "    for j,i in enumerate(frequencies):\n",
    "        \n",
    "        # Note given we are assuming linear regression we can use the formulae\n",
    "        # 7.23 - 7.25 in the Huges and Hayes book\n",
    "        alpha_i = voltage_errors[j]\n",
    "        a_cc += (1/(alpha_i**2))\n",
    "        a_cm += (i/(alpha_i**2))\n",
    "        a_mm += (i**2/(alpha_i**2))\n",
    "    a_mc = a_cm\n",
    "    curvature_matrix = np.matrix([[a_cc,a_cm],[a_mc,a_mm]])\n",
    "\n",
    "    return curvature_matrix\n",
    "one_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78184cb31bed24e47c94f61a8b114d83",
     "grade": false,
     "grade_id": "cell-297224eb42753407",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) Invert this to give the error matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b4369cfbe304ff7073c1a088d095bd2",
     "grade": false,
     "grade_id": "cell-f1181bd93715c586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('linear_regression.csv')\n",
    "frequencies = data.iloc[:,0]\n",
    "voltages = data.iloc[:,1]\n",
    "voltage_errors = data.iloc[:,2]\n",
    "\n",
    "def one_ii():\n",
    "    '''Your function should return something of the form np.matrix([[a_cc,a_cm],[a_mc,a_mm]])'''\n",
    "\n",
    "    curvature_matrix = one_i()\n",
    "    inverted_matrix = curvature_matrix.I\n",
    "\n",
    "    return inverted_matrix\n",
    "\n",
    "one_ii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9a342516fec2d2ceb4fbf41a49971db",
     "grade": false,
     "grade_id": "cell-2bd4c55c097ad632",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) What are the uncertainties in the slope and intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c12723340c6ed64c4568aadcdefaeee8",
     "grade": false,
     "grade_id": "cell-6ff81eb1afbe53e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('linear_regression.csv')\n",
    "frequencies = data.iloc[:,0]\n",
    "voltages = data.iloc[:,1]\n",
    "voltage_errors = data.iloc[:,2]\n",
    "\n",
    "def one_iii():\n",
    "    slope_uncertainty = 0\n",
    "    intercept_uncertainty = 0\n",
    "\n",
    "    error_matrix = one_ii()\n",
    "    slope_uncertainty = np.sqrt(error_matrix[1,1])\n",
    "    intercept_uncertainty = np.sqrt(error_matrix[0,0])\n",
    "\n",
    "    return slope_uncertainty,intercept_uncertainty\n",
    "\n",
    "one_iii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45f02ed5a50bf7ae72e41affea015045",
     "grade": false,
     "grade_id": "cell-4e08fdb22973b46c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iv) Comment on your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bc6dc2371803611401f6b28bcf07543",
     "grade": false,
     "grade_id": "cell-f68bfa4e8b879207",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We did the same analysis last week and got the same answer with a different method.\n",
    "\n",
    "The diagonal elements of the error matrix are also not equal to the inverse of the diagonal elements of the curvature matrix and therefore suggest a correlation between the errors in the gradient and intercept. More specifically, since the off-diagonal elemements of the error matrix are negative (and therefore so are the values of the off-diagonal correlation matrix), the two variables are negatively correlated.\n",
    "\n",
    "The error on the intercept is much larger than the error on the gradient. Given that the errors in the y-data (the voltage) are large relative to the negligible error in the x-data (frequency) this is not surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ebea22fca15c6627611903ae540c785",
     "grade": false,
     "grade_id": "cell-e98b996e8522b95f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2: Using a calibration curve\n",
    "\n",
    "A frequently encountered case where the correlation of the uncertainties must be taken into account is that of a calibration curve.  Consider the following set of measurements from an optical-activity experiment, where the angle of rotation of a plane-polarized light beam, $\\theta$, is measured as a function of the independent variable, the concentration, $C$, of a sucrose solution. \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{lcccc}\n",
    "\\hline\n",
    "C \\mbox{ (g cm$^{-3}$)} &0.025&0.05&0.075&0.100\\\\\n",
    "\\theta \\mbox{ (degrees)}&10.7&21.6&32.4&43.1\\\\\n",
    "\\hline\n",
    "C \\mbox{ (g cm$^{-3}$)}&0.125&0.150&0.175\\\\\n",
    "\\theta \\mbox{ (degrees)}&53.9&64.9&75.4\\\\\n",
    "\\hline\n",
    "\\end{array} \n",
    "\\end{equation}\n",
    "\n",
    "The errors in the angle measurement are all $0.1^{\\circ}$, the errors in the concentration are negligible.  A straight line  fit to the data yields  a gradient of $431.7\\,^{\\circ}\\mbox{ g$^{-1}$ cm$^{3}$}$, and intercept $-0.03^{\\circ}$. This data is contained in 'optical_activity.csv'.\n",
    "\n",
    "<bf>\n",
    "Required:\n",
    "<bf>\n",
    ">(i) Show that the curvature matrix, $\\mathsf{A}$, is given by \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{A}=\\left[\\begin{array}{cc}\n",
    "700\\left((^{\\circ})^{-2}\\right)&70\\left((^{\\circ})^{-2}\\mbox{g cm$^{-3}$}\\right)\\\\\n",
    "70\\left((^{\\circ})^{-2}\\mbox{g cm$^{-3}$}\\right)&8.75\\left((\\mbox{g/$^\\circ$ cm$^{3})^2$}\\right)\\\\\n",
    "\\end{array}\\right] ,\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    ">and that the error matrix  is \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathsf{C}=\\left[\\begin{array}{cc}\n",
    "0.00714\\left((^{\\circ})^2\\right)&-0.0571\\left((^{\\circ})^2\\mbox{g$^{-1}$cm$^{3}$}\\right)\\\\\n",
    "-0.0571\\left((^{\\circ})^2\\mbox{g$^{-1}$cm$^{3}$}\\right)&0.571\\left((^{\\circ})^2\\mbox{g$^{-2}$ cm$^{6}$}\\right)\\\\\n",
    "\\end{array}\\right] .\n",
    "\\end{equation}\n",
    "\n",
    "The entry for the intercept is in the top left-hand corner, that for the gradient in the bottom right-hand corner.  \n",
    "<bf>\n",
    ">(ii) Calculate the associated correlation matrix.  \n",
    "\n",
    "Use the  entries of the error matrix to answer the following  questions: \n",
    "<bf>\n",
    ">(iii) What are the uncertainties in the best-fit intercept and gradient? \n",
    "<bf>\n",
    ">(iv) What optical rotation is expected for a known concentration of $C=0.080g cm^{-3}$, and what is the uncertainty? \n",
    "<bf>\n",
    ">(v) What is the concentration given a measured rotation of $\\theta=70.3^{\\circ}$ and what is the uncertainty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b9d6bc6483f612aac689ff84d0481b9",
     "grade": false,
     "grade_id": "cell-b0e0b1d18dd53d75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Verify the curvature matrix and the error matrix above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2037a9af6b14f6b13b4cdd1ea5622b7f",
     "grade": false,
     "grade_id": "cell-90c242e605b9f033",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('optical_activity.csv')\n",
    "concentrations = data.iloc[:,0]\n",
    "angles = data.iloc[:,1]\n",
    "angle_errors = data.iloc[:,2]\n",
    "\n",
    "def two_i():\n",
    "    '''Your function should return something of the form np.matrix([[a_cc,a_cm],[a_mc,a_mm]]). Must return the curvature and error matricies)'''\n",
    "    curvature_matrix = 0\n",
    "    error_matrix = 0\n",
    "\n",
    "    a_cc = 0\n",
    "    a_cm = 0\n",
    "    a_mm = 0\n",
    "    for j,i in enumerate(concentrations):\n",
    "        alpha_i = angle_errors[j]\n",
    "        a_cc += (1/(alpha_i**2))\n",
    "        a_cm += (i/(alpha_i**2))\n",
    "        a_mm += (i**2/(alpha_i**2))\n",
    "    a_mc = a_cm\n",
    "    \n",
    "    curvature_matrix = np.matrix([[a_cc,a_cm],[a_mc,a_mm]])\n",
    "    error_matrix = curvature_matrix.I\n",
    "\n",
    "    return curvature_matrix,error_matrix\n",
    "\n",
    "two_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "990ff56998e5024fc935210d27d2cf79",
     "grade": false,
     "grade_id": "cell-b667bab6b908e819",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) Calculate the associated correlation matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae461cfba2e9b0d1d5defe7902274567",
     "grade": false,
     "grade_id": "cell-6a7fa0e40768028d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('optical_activity.csv')\n",
    "concentrations = data.iloc[:,0]\n",
    "angles = data.iloc[:,1]\n",
    "angle_errors = data.iloc[:,2]\n",
    "\n",
    "def two_ii():\n",
    "    '''Your function should return something of the form np.matrix([[a_cc,a_cm],[a_mc,a_mm]])'''\n",
    "    \n",
    "    matricies = two_i()\n",
    "    error_matrix = matricies[1]\n",
    "    diagonal_element = 1\n",
    "    off_diagonal = error_matrix[0,1]/np.sqrt(error_matrix[0,0]*error_matrix[1,1])\n",
    "    correlation_matrix = np.matrix([[1,off_diagonal],[off_diagonal,1]])\n",
    "\n",
    "    return correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e80d2b10c194f70a6619124bfdf0cac",
     "grade": false,
     "grade_id": "cell-45c82ff7c57d0ccb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) What are the uncertainties in the best-fit intercept and gradient? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ed1682ed5a9eb0702f040541fcf6bff",
     "grade": false,
     "grade_id": "cell-f32635e579d41db7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('optical_activity.csv')\n",
    "concentrations = data.iloc[:,0]\n",
    "angles = data.iloc[:,1]\n",
    "angle_errors = data.iloc[:,2]\n",
    "\n",
    "def two_iii():\n",
    "    '''Your function should return the uncertainty in the gradient and intercept'''\n",
    "    gradient_uncertainty = 0\n",
    "    intercept_uncertainty = 0\n",
    "\n",
    "    matricies = two_i()\n",
    "    error_matrix = matricies[1]\n",
    "    intercept_uncertainty = np.sqrt(error_matrix[0,0])\n",
    "    gradient_uncertainty = np.sqrt(error_matrix[1,1])\n",
    "\n",
    "    return gradient_uncertainty,intercept_uncertainty\n",
    "\n",
    "two_iii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "586e6c363046b6e648d44a6654206a23",
     "grade": false,
     "grade_id": "cell-245627a0850cbab9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iv) What optical rotation is expected for a known concentration of $C=0.080g cm^{-3}$, and what is the uncertainty? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1f6035f71189a9fdb8a421a73bbfa48",
     "grade": false,
     "grade_id": "cell-48ce90c9edb9a1af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('optical_activity.csv')\n",
    "concentrations = data.iloc[:,0]\n",
    "angles = data.iloc[:,1]\n",
    "angle_errors = data.iloc[:,2]\n",
    "\n",
    "def two_iv():\n",
    "    '''Your function should return the angle and the uncertainty'''\n",
    "    angle = 0\n",
    "    uncertainty = 0\n",
    "\n",
    "    matricies = two_i()\n",
    "    error_matrix = matricies[1]\n",
    "    angle = (431.7*0.08)-0.03\n",
    "    \n",
    "    # combine errors together\n",
    "    uncertainty = np.sqrt(((0.08**2)*error_matrix[1,1])+error_matrix[0,0]+(2*0.08*error_matrix[0,1]))\n",
    "\n",
    "    return angle,uncertainty\n",
    "\n",
    "two_iv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b5712718dfa312d87631364c44e4e58",
     "grade": false,
     "grade_id": "cell-ce7c8453308eee52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (v) What is the concentration given a measured rotation of $\\theta=70.3^{\\circ}$ and what is the uncertainty? You must return your answer in $gcm^{-3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad3743faa9582123884cf0c9299587f3",
     "grade": false,
     "grade_id": "cell-2a210b206abe39ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('optical_activity.csv')\n",
    "concentrations = data.iloc[:,0]\n",
    "angles = data.iloc[:,1]\n",
    "angle_errors = data.iloc[:,2]\n",
    "\n",
    "def two_v():\n",
    "    '''Your function should return the concentration and uncertainty'''\n",
    "\n",
    "    matricies = two_i()\n",
    "    error_matrix = matricies[1]\n",
    "    concentration = 70.33/431.7 #Should be 0.16291 gcm^-3\n",
    "    uncertainty = (1/431.7)*np.sqrt(((0.16291**2)*0.571)+0.00714+(2*0.16291*(-0.0571)))\n",
    "\n",
    "    return concentration,uncertainty\n",
    "\n",
    "two_v()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b5f308378db2ba51e4f858d97ff77a5",
     "grade": false,
     "grade_id": "cell-68476541a0ef792b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 3: Error bars from a $\\chi^2$ minimisation to a non-linear function\n",
    "\n",
    "In this question we will analyse the data shown in the figure below, which is an X-ray spectrum as a function of angle.\n",
    "\n",
    "![title](diffraction.JPG)\n",
    " \n",
    "The data is contained in the file 'LorentzianData.csv'. There are three columns: the angle, the signal (in counts per second), and the error.  The number of X-rays counted in 20 seconds was recorded.\n",
    "\n",
    "The model to describe the data has four parameters:  the height of the Lorentzian lineshape, $S_0$; the angle at which the peak is centered, $\\theta_{0}$;\n",
    " the angular width of the peak, $\\Delta\\theta$; and a constant background offset, $S_{\\rm bgd}$. Mathematically, the signal, $S$, is of the form:\n",
    "\\begin{equation}\n",
    "S=S_{\\rm bgd}+\\frac{S_{0}}{1+4\\left(\\frac{\\theta-\\theta_{0}}{\\Delta\\theta}\\right)^2}.\n",
    "\\end{equation}\n",
    "\n",
    "and the function is defined by `lorentzian(theta, s_0, s_bgd,delta_theta,theta_0)`.\n",
    "\n",
    "Required:\n",
    "<bf>\n",
    ">(i) Explain how the error in the count rate was calculated.\n",
    "<bf>\n",
    ">(ii) Perform a $\\chi^2$ minimisation.  What are the best-fit parameters?\n",
    "<bf>\n",
    ">(iii) Evaluate the error matrix.\n",
    "<bf>\n",
    ">(iv) Calculate the correlation matrix.\n",
    "<bf>\n",
    ">(v) What are the uncertainties in the best-fit parameters?\n",
    "<bf>\n",
    ">(vi) If you can plot contour plots, show the $\\chi^2$ contours for \n",
    "<bf>\n",
    ">>(a) background--peak centre. \n",
    "<bf>\n",
    ">>(b) background--peak width.  \n",
    "<bf>\n",
    ">These figures are shown in figure 6.11 of Hughes and Hase. Comment on the shape of the contours.\n",
    "<bf>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0530f5dbe3e2d8b6f472407bcaad90f7",
     "grade": false,
     "grade_id": "cell-b965fa7ac06be7a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (i) Explain how the error in the count rate was calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ad347c0698fe1ac8ba3050bdc3d209d",
     "grade": false,
     "grade_id": "cell-af660dec82aee39a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The errors were calculated using Poisson statistics. As each count rate was calculated by measuring the number of counts in $20$ s, the error in the rate was given by taking the square root of the number of counts calculated in this interval, and then dividing it by this length of time. Synbolically, if $\\tau$ is the amount of time the measurement was taken over and $\\dot{N}$ the calculated count rate, then\n",
    "\n",
    "$$\\alpha_{\\dot{N}} = \\frac{\\sqrt{\\dot{N}\\tau}}{\\tau} = \\sqrt{\\frac{\\dot{N}}{\\tau}}~.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "665283ee134e0eb19cfd5c3a42e9359a",
     "grade": false,
     "grade_id": "cell-f719a415310aea0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (ii) Perform a $\\chi^2$ minimisation.  What are the best-fit parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce2852e71eaa96a42438826b8bb0cad7",
     "grade": false,
     "grade_id": "cell-b803d7b2c879b923",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('LorentzianData.csv') \n",
    "\n",
    "def lorentzian(theta, s_0, s_bgd,delta_theta,theta_0):\n",
    "    return s_bgd+(s_0/(1+4*(((theta-theta_0)/delta_theta)**2)))\n",
    "\n",
    "def three_ii():\n",
    "    s_0 = 0\n",
    "    s_bgd = 0\n",
    "    delta_theta = 0\n",
    "    theta_0 = 0\n",
    "    covariance_matrix = 0\n",
    "    angles = data.iloc[:,0]\n",
    "    intensity = data.iloc[:,1]\n",
    "    intensity_errors = data.iloc[:,2]\n",
    "    \n",
    "   \n",
    "    guess = np.array([5.,1.,0.5,44.])\n",
    "    #guess = np.array([5.42,1.40,0.94,44.39])\n",
    "    popt,pcov= curve_fit(lorentzian, angles, intensity, guess, sigma=intensity_errors)\n",
    "    covariance_matrix = pcov\n",
    "    s_0= popt[0]\n",
    "    s_bgd = popt[1]\n",
    "    theta_0 = popt[3]\n",
    "    delta_theta = popt[2]\n",
    "    angles_1 = np.arange(39,50,0.01)\n",
    "    intensity_1 = []\n",
    "    for i in angles_1:\n",
    "        element = s_bgd + (s_0/(1+4*((i-theta_0)/delta_theta)**2))\n",
    "        intensity_1.append(element)\n",
    "  \n",
    "    return(s_0,s_bgd,delta_theta,theta_0,covariance_matrix)\n",
    "\n",
    "three_ii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87904b908543290acc213ed83b4cecb5",
     "grade": false,
     "grade_id": "cell-bbcc2ba2381e48e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iii) Evaluate the error matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8299beb82b414569df72b80e044082bf",
     "grade": false,
     "grade_id": "cell-4190be1416227f9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('LorentzianData.csv') \n",
    "\n",
    "def three_iii():\n",
    "    '''Your function should return something of the form np.matrix([[a_cc,a_cm],[a_mc,a_mm]])'''\n",
    "\n",
    "    cov_matrix = np.matrix(three_ii()[4])\n",
    "    error_matrix = cov_matrix\n",
    "\n",
    "    return error_matrix\n",
    "\n",
    "three_iii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42f08c41e201c4f69478238324328833",
     "grade": false,
     "grade_id": "cell-cdf84fe51f3f3f4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (iv) Calculate the correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0b1c3f1fe24d3dec075e4a48bce31f8",
     "grade": false,
     "grade_id": "cell-c7257914f67b1821",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('LorentzianData.csv') \n",
    "\n",
    "def three_iv():\n",
    "    '''Your function should return something of the form np.matrix([[a_cc,a_cm],[a_mc,a_mm]])'''\n",
    "\n",
    "    cov_matrix = np.matrix(three_ii()[4])\n",
    "    correlation_matrix = np.corrcoef(cov_matrix)\n",
    "    \n",
    "    return correlation_matrix\n",
    "\n",
    "three_iv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec44c4d4e4945968ef6f13a046eb14b0",
     "grade": false,
     "grade_id": "cell-e823d6820599ceee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (v) What are the uncertainties in the best-fit parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee20d44e82d67c49ffccc92879f5b3b2",
     "grade": false,
     "grade_id": "cell-e6553187fe7ba54a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('LorentzianData.csv') \n",
    "\n",
    "def three_v():\n",
    "    uncertainty_s_0 = 0\n",
    "    uncertainty_s_bgd = 0\n",
    "    uncertainty_delta_theta = 0\n",
    "    uncertainty_theta_0 = 0\n",
    "\n",
    "    error_mat = three_iii()\n",
    "    uncertainty_s_0 = np.sqrt(error_mat[0,0])\n",
    "    uncertainty_s_bgd = np.sqrt(error_mat[1,1])\n",
    "    uncertainty_delta_theta = np.sqrt(error_mat[2,2])\n",
    "    uncertainty_theta_0 = np.sqrt(error_mat[3,3])\n",
    "\n",
    "    return uncertainty_s_0,uncertainty_s_bgd,uncertainty_delta_theta,uncertainty_theta_0\n",
    "\n",
    "three_v()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0fa22dd08ae1adba1558e79de3cae68",
     "grade": false,
     "grade_id": "cell-6837d80f4935e327",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### (vi) These contours are shown in figure 6.11 of Hughes and Hase. Comment on the shape of the contours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "506673bda68e133a9d9047ba326f1939",
     "grade": false,
     "grade_id": "cell-9d235bfae599fba1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The contours are not entirely elliptical; this is due to the non-linear fit. The contours for the background-width plot are flatter near the minimum than those of the background-centre plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae6b10359f115ffac6039cdbbe8565fd",
     "grade": false,
     "grade_id": "cell-1847db7a2c78bfde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 4: Prove the following properties:\n",
    "\n",
    "Assume in this question that the uncertainties in $A$ and $B$ are correlated.\n",
    ">(i) If $Z=A\\pm B$, show that\n",
    "${\\displaystyle\\alpha_{Z}^2=\\alpha_{A}^2+\\alpha_{B}^2\\pm2\\alpha_{AB}}$.\n",
    "<bf>\n",
    ">(ii) If $Z=A\\times B$, show that\n",
    " ${\\displaystyle\\left(\\frac{\\alpha_Z}{Z}\\right)^2=\\left(\\frac{\\alpha_A}{A}\\right)^2+\\left(\\frac{\\alpha_B}{B}\\right)^2+2\\left(\\frac{\\alpha_{AB}}{AB}\\right)}$.\n",
    "<bf>\n",
    ">(iii) If ${\\displaystyle Z=\\frac{A}{B}}$, show that\n",
    "${\\displaystyle\\left(\\frac{\\alpha_Z}{Z}\\right)^2=\\left(\\frac{\\alpha_A}{A}\\right)^2+\\left(\\frac{\\alpha_B}{B}\\right)^2-2\\left(\\frac{\\alpha_{AB}}{AB}\\right)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ead36e9f18603a7873b25094c927c917",
     "grade": true,
     "grade_id": "cell-98dd0155ce1eafc8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
